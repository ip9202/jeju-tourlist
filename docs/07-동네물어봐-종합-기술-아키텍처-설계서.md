# "ë™ë„¤ë¬¼ì–´ë´" ì¢…í•© ê¸°ìˆ  ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ

## ğŸ“‹ ëª©ì°¨
1. [ì•„í‚¤í…ì²˜ ê°œìš”](#-ì•„í‚¤í…ì²˜-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜-ë‹¤ì´ì–´ê·¸ë¨)
3. [ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„](#-ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤-ì•„í‚¤í…ì²˜-ì„¤ê³„)
4. [í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì•„í‚¤í…ì²˜](#-í´ë¼ìš°ë“œ-ë„¤ì´í‹°ë¸Œ-ì•„í‚¤í…ì²˜)
5. [í™•ì¥ì„± ì„¤ê³„ ì „ëµ](#-í™•ì¥ì„±-ì„¤ê³„-ì „ëµ)
6. [ê³ ê°€ìš©ì„± ë° ì¬í•´ë³µêµ¬](#-ê³ ê°€ìš©ì„±-ë°-ì¬í•´ë³µêµ¬)
7. [ì„±ëŠ¥ ìµœì í™” ì „ëµ](#-ì„±ëŠ¥-ìµœì í™”-ì „ëµ)
8. [ê¸°ìˆ  ìŠ¤íƒ ì„ ì •](#-ê¸°ìˆ -ìŠ¤íƒ-ì„ ì •)
9. [ê°œë°œ ë° ë°°í¬ íŒŒì´í”„ë¼ì¸](#-ê°œë°œ-ë°-ë°°í¬-íŒŒì´í”„ë¼ì¸)
10. [ë¹„ìš© ìµœì í™” ì „ëµ](#-ë¹„ìš©-ìµœì í™”-ì „ëµ)

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

### ì„¤ê³„ ì² í•™

"ë™ë„¤ë¬¼ì–´ë´"ëŠ” ì œì£¼ë„ì—ì„œ ì‹œì‘í•˜ì—¬ ì „êµ­ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ì§€ì—­ ê¸°ë°˜ Q&A ì»¤ë®¤ë‹ˆí‹° ì„œë¹„ìŠ¤ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ì›ì¹™ì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ê³„ë©ë‹ˆë‹¤:

#### 1. í™•ì¥ì„± ìš°ì„  ì„¤ê³„ (Scalability First)
- **ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥**: íŠ¸ë˜í”½ ì¦ê°€ì— ë”°ë¥¸ ì„œë²„ ìë™ ìŠ¤ì¼€ì¼ë§
- **ì§€ì—­ë³„ í™•ì¥ ëŒ€ë¹„**: ì œì£¼ë„ â†’ ë¶€ì‚°, ê°•ë¦‰ ë“± ì ì§„ì  í™•ì¥ ê³ ë ¤
- **ê¸€ë¡œë²Œ í™•ì¥ ê°€ëŠ¥**: í–¥í›„ í•´ì™¸ ì§„ì¶œì‹œ ë©€í‹°ë¦¬ì „ ì§€ì›

#### 2. ì•ˆì •ì„± ë° ê°€ìš©ì„± (Reliability & Availability)
- **99.9% ê°€ìš©ì„± ëª©í‘œ**: ì—°ê°„ ë‹¤ìš´íƒ€ì„ 8.76ì‹œê°„ ì´í•˜
- **ì¥ì•  í—ˆìš© ì„¤ê³„**: ë¶€ë¶„ ì¥ì•  ë°œìƒì‹œì—ë„ ì„œë¹„ìŠ¤ ì§€ì†
- **ìë™ ë³µêµ¬**: ì¸í”„ë¼ ì¥ì• ì‹œ ìë™ í˜ì¼ì˜¤ë²„

#### 3. ì„±ëŠ¥ ìµœì í™” (Performance Optimization)
- **10ë¶„ ë‚´ ë‹µë³€ ëª©í‘œ**: ì œì£¼ë„ íŠ¹ì„± ë°˜ì˜í•œ ì‹¤ì‹œê°„ ì‘ë‹µ ì‹œìŠ¤í…œ
- **ì €ì§€ì—° ë„¤íŠ¸ì›Œí¬**: Edge CDN í™œìš©ìœ¼ë¡œ í•œêµ­ ì „ì—­ 100ms ì´í•˜ ì‘ë‹µ
- **íš¨ìœ¨ì  ìºì‹±**: ë‹¤ì¸µ ìºì‹±ìœ¼ë¡œ DB ë¶€í•˜ ìµœì†Œí™”

#### 4. ë¹„ìš© íš¨ìœ¨ì„± (Cost Efficiency)
- **ë‹¨ê³„ë³„ ë¹„ìš© ìµœì í™”**: MVP â†’ í™•ì¥ ë‹¨ê³„ë³„ ì¸í”„ë¼ ë¹„ìš© ê´€ë¦¬
- **ì„œë²„ë¦¬ìŠ¤ ìš°ì„ **: íŠ¸ë˜í”½ ë³€ë™ì— ë”°ë¥¸ ìë™ ë¹„ìš© ì¡°ì ˆ
- **ì˜¤í”ˆì†ŒìŠ¤ í™œìš©**: ë¼ì´ì„ ìŠ¤ ë¹„ìš© ìµœì†Œí™”

### ì•„í‚¤í…ì²˜ ëª©í‘œ

```mermaid
graph TB
    subgraph "Phase 1: MVP (0-1k users)"
        A[Monolithic Architecture]
        A --> B[Single Region Deployment]
        A --> C[Basic Monitoring]
    end

    subgraph "Phase 2: Growth (1k-10k users)"
        D[Microservices Migration]
        D --> E[Multi-AZ Deployment]
        D --> F[Advanced Monitoring]
    end

    subgraph "Phase 3: Scale (10k-100k users)"
        G[Multi-Region Architecture]
        G --> H[Global CDN]
        G --> I[Auto-scaling]
    end

    subgraph "Phase 4: Enterprise (100k+ users)"
        J[Global Multi-Cloud]
        J --> K[Edge Computing]
        J --> L[ML/AI Integration]
    end

    A --> D --> G --> J
```

---

## ğŸ›ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

### ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
C4Context
    title System Context Diagram for "ë™ë„¤ë¬¼ì–´ë´"

    Person(user, "ì¼ë°˜ ì‚¬ìš©ì", "ì œì£¼ ì—¬í–‰ì ë° í˜„ì§€ì¸")
    Person(admin, "ê´€ë¦¬ì", "ì»¤ë®¤ë‹ˆí‹° ìš´ì˜ì§„")
    Person(business, "ì œíœ´ì—…ì²´", "ë§›ì§‘, ìˆ™ì†Œ ì‚¬ì—…ì")

    System(dongne, "ë™ë„¤ë¬¼ì–´ë´ ì‹œìŠ¤í…œ", "ì§€ì—­ ê¸°ë°˜ Q&A ì»¤ë®¤ë‹ˆí‹° í”Œë«í¼")

    System_Ext(kakao, "ì¹´ì¹´ì˜¤ ì„œë¹„ìŠ¤", "ë¡œê·¸ì¸, ë§µ, ì•Œë¦¼")
    System_Ext(naver, "ë„¤ì´ë²„ ì„œë¹„ìŠ¤", "ë¡œê·¸ì¸, ë§µ, í´ë¼ìš°ë“œ")
    System_Ext(google, "Google ì„œë¹„ìŠ¤", "ë¡œê·¸ì¸, ë§µ, í´ë¼ìš°ë“œ")
    System_Ext(aws, "AWS", "í´ë¼ìš°ë“œ ì¸í”„ë¼")
    System_Ext(payment, "ê²°ì œ ì‹œìŠ¤í…œ", "í¬ì¸íŠ¸ ì¶©ì „, í”„ë¦¬ë¯¸ì—„")

    Rel(user, dongne, "ì§ˆë¬¸/ë‹µë³€ ì‘ì„±", "HTTPS")
    Rel(admin, dongne, "ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§", "HTTPS")
    Rel(business, dongne, "ì—…ì²´ ì •ë³´ ê´€ë¦¬", "HTTPS")

    Rel(dongne, kakao, "ì†Œì…œ ë¡œê·¸ì¸, ì§€ë„ API")
    Rel(dongne, naver, "ì†Œì…œ ë¡œê·¸ì¸, ì§€ë„ API")
    Rel(dongne, google, "ì†Œì…œ ë¡œê·¸ì¸, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤")
    Rel(dongne, aws, "ì¸í”„ë¼ ë° ì„œë¹„ìŠ¤")
    Rel(dongne, payment, "ê²°ì œ ì²˜ë¦¬")
```

### ì»¨í…Œì´ë„ˆ ë ˆë²¨ ì•„í‚¤í…ì²˜

```mermaid
C4Container
    title Container Diagram for "ë™ë„¤ë¬¼ì–´ë´"

    Person(user, "ì‚¬ìš©ì")

    Container_Boundary(c1, "ë™ë„¤ë¬¼ì–´ë´ ì‹œìŠ¤í…œ") {
        Container(webapp, "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜", "Next.js", "ë°˜ì‘í˜• ì›¹ UI")
        Container(mobile, "ëª¨ë°”ì¼ ì•±", "React Native", "iOS/Android ì•±")
        Container(api, "API Gateway", "Express.js", "API ë¼ìš°íŒ… ë° ì¸ì¦")

        Container(user_service, "ì‚¬ìš©ì ì„œë¹„ìŠ¤", "Node.js", "ì¸ì¦, í”„ë¡œí•„ ê´€ë¦¬")
        Container(qa_service, "Q&A ì„œë¹„ìŠ¤", "Node.js", "ì§ˆë¬¸, ë‹µë³€, ì±„íƒ")
        Container(notification_service, "ì•Œë¦¼ ì„œë¹„ìŠ¤", "Node.js", "ì‹¤ì‹œê°„ ì•Œë¦¼")
        Container(location_service, "ìœ„ì¹˜ ì„œë¹„ìŠ¤", "Node.js", "GPS, ì§€ì—­ ê´€ë¦¬")
        Container(search_service, "ê²€ìƒ‰ ì„œë¹„ìŠ¤", "Node.js", "í†µí•© ê²€ìƒ‰")

        ContainerDb(postgres, "PostgreSQL", "ê´€ê³„í˜• DB", "ì£¼ìš” ë°ì´í„° ì €ì¥")
        ContainerDb(redis, "Redis", "ìºì‹œ DB", "ì„¸ì…˜, ìºì‹œ")
        ContainerDb(elasticsearch, "Elasticsearch", "ê²€ìƒ‰ DB", "ì „ë¬¸ ê²€ìƒ‰")
        ContainerDb(s3, "AWS S3", "ê°ì²´ ìŠ¤í† ë¦¬ì§€", "ì´ë¯¸ì§€, íŒŒì¼")
    }

    Container_Ext(kakao_api, "ì¹´ì¹´ì˜¤ API")
    Container_Ext(monitoring, "ëª¨ë‹ˆí„°ë§", "DataDog/CloudWatch")

    Rel(user, webapp, "ì‚¬ìš©", "HTTPS")
    Rel(user, mobile, "ì‚¬ìš©", "HTTPS")

    Rel(webapp, api, "API í˜¸ì¶œ", "HTTPS")
    Rel(mobile, api, "API í˜¸ì¶œ", "HTTPS")

    Rel(api, user_service, "ì‚¬ìš©ì ìš”ì²­")
    Rel(api, qa_service, "Q&A ìš”ì²­")
    Rel(api, notification_service, "ì•Œë¦¼ ìš”ì²­")
    Rel(api, location_service, "ìœ„ì¹˜ ìš”ì²­")
    Rel(api, search_service, "ê²€ìƒ‰ ìš”ì²­")

    Rel(user_service, postgres, "ì½ê¸°/ì“°ê¸°")
    Rel(qa_service, postgres, "ì½ê¸°/ì“°ê¸°")
    Rel(notification_service, redis, "ì½ê¸°/ì“°ê¸°")
    Rel(search_service, elasticsearch, "ì½ê¸°/ì“°ê¸°")

    Rel(api, kakao_api, "ì™¸ë¶€ API í˜¸ì¶œ")
    Rel(api, monitoring, "ë©”íŠ¸ë¦­ ì „ì†¡")
```

### ë°°í¬ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ì‚¬ìš©ì ë ˆì´ì–´"
        WEB[ì›¹ ë¸Œë¼ìš°ì €]
        MOBILE[ëª¨ë°”ì¼ ì•±]
        ADMIN[ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ]
    end

    subgraph "CDN & ë¡œë“œë°¸ëŸ°ì„œ"
        CDN[CloudFront CDN]
        ALB[Application Load Balancer]
    end

    subgraph "ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆì´ì–´ (Multi-AZ)"
        subgraph "AZ-1"
            WEB1[Next.js App]
            API1[API Server]
        end
        subgraph "AZ-2"
            WEB2[Next.js App]
            API2[API Server]
        end
        subgraph "AZ-3"
            WEB3[Next.js App]
            API3[API Server]
        end
    end

    subgraph "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë ˆì´ì–´"
        USER_SVC[User Service]
        QA_SVC[Q&A Service]
        NOTIF_SVC[Notification Service]
        LOC_SVC[Location Service]
        SEARCH_SVC[Search Service]
    end

    subgraph "ë°ì´í„° ë ˆì´ì–´"
        subgraph "Primary DB"
            PG_MASTER[PostgreSQL Master]
        end
        subgraph "Read Replicas"
            PG_SLAVE1[PostgreSQL Slave 1]
            PG_SLAVE2[PostgreSQL Slave 2]
        end
        REDIS_CLUSTER[Redis Cluster]
        ES_CLUSTER[Elasticsearch Cluster]
        S3[AWS S3]
    end

    subgraph "ì™¸ë¶€ ì„œë¹„ìŠ¤"
        KAKAO[ì¹´ì¹´ì˜¤ API]
        NAVER[ë„¤ì´ë²„ API]
        GOOGLE[êµ¬ê¸€ API]
    end

    subgraph "ëª¨ë‹ˆí„°ë§ & ë¡œê¹…"
        CLOUDWATCH[CloudWatch]
        DATADOG[DataDog]
        SENTRY[Sentry]
        ELK[ELK Stack]
    end

    WEB --> CDN
    MOBILE --> ALB
    ADMIN --> ALB

    CDN --> ALB
    ALB --> WEB1
    ALB --> WEB2
    ALB --> WEB3

    WEB1 --> API1
    WEB2 --> API2
    WEB3 --> API3

    API1 --> USER_SVC
    API1 --> QA_SVC
    API2 --> NOTIF_SVC
    API2 --> LOC_SVC
    API3 --> SEARCH_SVC

    USER_SVC --> PG_MASTER
    QA_SVC --> PG_SLAVE1
    LOC_SVC --> PG_SLAVE2

    NOTIF_SVC --> REDIS_CLUSTER
    SEARCH_SVC --> ES_CLUSTER

    API1 --> S3
    API2 --> S3
    API3 --> S3

    API1 --> KAKAO
    API1 --> NAVER
    API1 --> GOOGLE

    API1 --> CLOUDWATCH
    API2 --> DATADOG
    API3 --> SENTRY
```

---

## ğŸ”§ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì„œë¹„ìŠ¤ ë¶„í•  ì „ëµ

#### 1. ë„ë©”ì¸ ê¸°ë°˜ ë¶„í•  (Domain-Driven Design)

```typescript
// ì„œë¹„ìŠ¤ ê²½ê³„ ì •ì˜
interface ServiceBoundary {
  name: string;
  domain: string;
  responsibilities: string[];
  interfaces: APIEndpoint[];
  databases: Database[];
  dependencies: ServiceDependency[];
}

const services: ServiceBoundary[] = [
  {
    name: "user-service",
    domain: "User Management",
    responsibilities: [
      "ì‚¬ìš©ì ì¸ì¦ ë° ì¸ê°€",
      "í”„ë¡œí•„ ê´€ë¦¬",
      "ì†Œì…œ ë¡œê·¸ì¸ í†µí•©",
      "ê¶Œí•œ ê´€ë¦¬"
    ],
    interfaces: [
      { method: "POST", path: "/auth/login", description: "ë¡œê·¸ì¸" },
      { method: "GET", path: "/users/:id", description: "ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ" },
      { method: "PUT", path: "/users/:id", description: "í”„ë¡œí•„ ì—…ë°ì´íŠ¸" }
    ],
    databases: ["postgres-users", "redis-sessions"],
    dependencies: ["external-oauth-providers"]
  },
  {
    name: "qa-service",
    domain: "Question & Answer",
    responsibilities: [
      "ì§ˆë¬¸ ìƒì„±, ìˆ˜ì •, ì‚­ì œ",
      "ë‹µë³€ ìƒì„±, ìˆ˜ì •, ì‚­ì œ",
      "ì±„íƒ ì‹œìŠ¤í…œ ê´€ë¦¬",
      "í¬ì¸íŠ¸ ì ë¦½ ì²˜ë¦¬"
    ],
    interfaces: [
      { method: "POST", path: "/questions", description: "ì§ˆë¬¸ ë“±ë¡" },
      { method: "POST", path: "/answers", description: "ë‹µë³€ ë“±ë¡" },
      { method: "PUT", path: "/answers/:id/accept", description: "ë‹µë³€ ì±„íƒ" }
    ],
    databases: ["postgres-qa"],
    dependencies: ["user-service", "notification-service"]
  },
  {
    name: "notification-service",
    domain: "Real-time Notifications",
    responsibilities: [
      "ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡",
      "í‘¸ì‹œ ì•Œë¦¼ ê´€ë¦¬",
      "ì´ë©”ì¼ ì•Œë¦¼",
      "ì•Œë¦¼ ì„¤ì • ê´€ë¦¬"
    ],
    interfaces: [
      { method: "POST", path: "/notifications", description: "ì•Œë¦¼ ì „ì†¡" },
      { method: "GET", path: "/notifications/:userId", description: "ì•Œë¦¼ ëª©ë¡" }
    ],
    databases: ["redis-notifications"],
    dependencies: ["user-service", "external-push-services"]
  },
  {
    name: "location-service",
    domain: "Geographic Services",
    responsibilities: [
      "ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰",
      "ì§€ì—­ ê´€ë¦¬",
      "GPS ì¢Œí‘œ ì²˜ë¦¬",
      "ê±°ë¦¬ ê³„ì‚°"
    ],
    interfaces: [
      { method: "POST", path: "/locations", description: "ìœ„ì¹˜ ë“±ë¡" },
      { method: "GET", path: "/locations/nearby", description: "ì£¼ë³€ ê²€ìƒ‰" }
    ],
    databases: ["postgres-geo"],
    dependencies: ["external-map-apis"]
  },
  {
    name: "search-service",
    domain: "Search & Discovery",
    responsibilities: [
      "í†µí•© ê²€ìƒ‰",
      "í•´ì‹œíƒœê·¸ ê´€ë¦¬",
      "ê²€ìƒ‰ ìµœì í™”",
      "íŠ¸ë Œë”© ë¶„ì„"
    ],
    interfaces: [
      { method: "GET", path: "/search", description: "í†µí•© ê²€ìƒ‰" },
      { method: "GET", path: "/trending", description: "íŠ¸ë Œë”© í•´ì‹œíƒœê·¸" }
    ],
    databases: ["elasticsearch"],
    dependencies: ["qa-service", "user-service"]
  }
];
```

#### 2. ì„œë¹„ìŠ¤ ê°„ í†µì‹  íŒ¨í„´

```typescript
// ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹  (Event-Driven Architecture)
interface EventPattern {
  eventType: string;
  publisher: string;
  subscribers: string[];
  payload: any;
  deliveryGuarantee: 'at-least-once' | 'exactly-once' | 'at-most-once';
}

const eventPatterns: EventPattern[] = [
  {
    eventType: "user.registered",
    publisher: "user-service",
    subscribers: ["notification-service", "analytics-service"],
    payload: {
      userId: "string",
      email: "string",
      createdAt: "timestamp"
    },
    deliveryGuarantee: "at-least-once"
  },
  {
    eventType: "question.created",
    publisher: "qa-service",
    subscribers: ["notification-service", "search-service", "location-service"],
    payload: {
      questionId: "string",
      userId: "string",
      location: "geopoint",
      hashtags: "string[]",
      urgency: "normal | urgent"
    },
    deliveryGuarantee: "exactly-once"
  },
  {
    eventType: "answer.accepted",
    publisher: "qa-service",
    subscribers: ["notification-service", "user-service"],
    payload: {
      answerId: "string",
      questionId: "string",
      answererId: "string",
      questionerId: "string",
      points: "number"
    },
    deliveryGuarantee: "exactly-once"
  }
];
```

#### 3. API Gateway ì„¤ê³„

```typescript
// API Gateway ë¼ìš°íŒ… ê·œì¹™
interface RouteRule {
  path: string;
  method: string;
  service: string;
  version: string;
  authentication: boolean;
  rateLimit: RateLimit;
  caching: CacheConfig;
}

const apiRoutes: RouteRule[] = [
  {
    path: "/api/v1/auth/*",
    method: "*",
    service: "user-service",
    version: "v1",
    authentication: false,
    rateLimit: { requests: 10, window: "1m" },
    caching: { enabled: false }
  },
  {
    path: "/api/v1/questions",
    method: "GET",
    service: "qa-service",
    version: "v1",
    authentication: false,
    rateLimit: { requests: 100, window: "1m" },
    caching: { enabled: true, ttl: "5m" }
  },
  {
    path: "/api/v1/questions",
    method: "POST",
    service: "qa-service",
    version: "v1",
    authentication: true,
    rateLimit: { requests: 5, window: "1m" },
    caching: { enabled: false }
  },
  {
    path: "/api/v1/search",
    method: "GET",
    service: "search-service",
    version: "v1",
    authentication: false,
    rateLimit: { requests: 50, window: "1m" },
    caching: { enabled: true, ttl: "10m" }
  }
];
```

#### 4. ì„œë¹„ìŠ¤ ë©”ì‹œ (Service Mesh) êµ¬ì„±

```yaml
# Istio ì„œë¹„ìŠ¤ ë©”ì‹œ ì„¤ì •
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: dongne-services
spec:
  hosts:
  - api.dongnemuleoboa.com
  http:
  - match:
    - uri:
        prefix: "/api/v1/auth"
    route:
    - destination:
        host: user-service
        port:
          number: 3001
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
  - match:
    - uri:
        prefix: "/api/v1/questions"
    route:
    - destination:
        host: qa-service
        port:
          number: 3002
    timeout: 30s
  - match:
    - uri:
        prefix: "/api/v1/notifications"
    route:
    - destination:
        host: notification-service
        port:
          number: 3003
    timeout: 10s

---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: user-service-circuit-breaker
spec:
  host: user-service
  trafficPolicy:
    circuitBreaker:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
    loadBalancer:
      simple: LEAST_CONN
```

---

## â˜ï¸ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì•„í‚¤í…ì²˜

### ì»¨í…Œì´ë„ˆí™” ì „ëµ

#### 1. Docker ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ

```dockerfile
# ì‚¬ìš©ì ì„œë¹„ìŠ¤ Dockerfile
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build
RUN npm prune --production

FROM node:18-alpine AS runtime
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001
WORKDIR /app
COPY --from=build --chown=nextjs:nodejs /app/dist ./dist
COPY --from=build --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=build --chown=nextjs:nodejs /app/package.json ./package.json

USER nextjs
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

CMD ["node", "dist/index.js"]
```

#### 2. Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸

```yaml
# user-service ë°°í¬ ì„¤ì •
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  labels:
    app: user-service
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
        version: v1
    spec:
      containers:
      - name: user-service
        image: dongne/user-service:v1.0.0
        ports:
        - containerPort: 3000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: user-service-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: jwt-secret
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
      volumes:
      - name: config-volume
        configMap:
          name: user-service-config

---
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user-service
  ports:
  - port: 80
    targetPort: 3000
    protocol: TCP
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### 3. Helm ì°¨íŠ¸ êµ¬ì¡°

```yaml
# Chart.yaml
apiVersion: v2
name: dongne-services
description: ë™ë„¤ë¬¼ì–´ë´ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ Helm ì°¨íŠ¸
type: application
version: 1.0.0
appVersion: "1.0.0"

dependencies:
- name: postgresql
  version: 11.6.12
  repository: https://charts.bitnami.com/bitnami
  condition: postgresql.enabled
- name: redis
  version: 16.13.2
  repository: https://charts.bitnami.com/bitnami
  condition: redis.enabled
- name: elasticsearch
  version: 19.5.0
  repository: https://helm.elastic.co
  condition: elasticsearch.enabled

---
# values.yaml
global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: ""

services:
  userService:
    enabled: true
    replicaCount: 3
    image:
      repository: dongne/user-service
      tag: "v1.0.0"
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 20
      targetCPUUtilizationPercentage: 70

  qaService:
    enabled: true
    replicaCount: 3
    image:
      repository: dongne/qa-service
      tag: "v1.0.0"
      pullPolicy: IfNotPresent

postgresql:
  enabled: true
  auth:
    postgresPassword: "changeme"
    database: "dongne_db"
  primary:
    persistence:
      enabled: true
      size: "50Gi"
  readReplicas:
    replicaCount: 2

redis:
  enabled: true
  architecture: "replication"
  auth:
    enabled: true
    password: "changeme"
  master:
    persistence:
      enabled: true
      size: "10Gi"

elasticsearch:
  enabled: true
  replicas: 3
  minimumMasterNodes: 2
  volumeClaimTemplate:
    accessModes: ["ReadWriteOnce"]
    resources:
      requests:
        storage: "30Gi"
```

### ì„œë²„ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜ í†µí•©

#### 1. AWS Lambda í•¨ìˆ˜ (ë°°ì¹˜ ì‘ì—…ìš©)

```typescript
// íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ê³„ì‚° Lambda
import { APIGatewayProxyHandler } from 'aws-lambda';
import { ElasticsearchClient } from '@aws-sdk/client-elasticsearch';

export const calculateTrendingTags: APIGatewayProxyHandler = async (event) => {
  const es = new ElasticsearchClient({ region: 'ap-northeast-2' });

  try {
    // ì§€ë‚œ 24ì‹œê°„ í•´ì‹œíƒœê·¸ ì§‘ê³„
    const response = await es.send({
      index: 'questions',
      body: {
        aggs: {
          trending_tags: {
            terms: {
              field: 'hashtags',
              size: 20
            },
            aggs: {
              recent_usage: {
                filter: {
                  range: {
                    created_at: {
                      gte: 'now-24h'
                    }
                  }
                }
              }
            }
          }
        }
      }
    });

    // Redisì— ìºì‹œ ì €ì¥
    const trendingTags = response.aggregations.trending_tags.buckets;
    await redis.setex('trending:tags:24h', 3600, JSON.stringify(trendingTags));

    return {
      statusCode: 200,
      body: JSON.stringify({ trendingTags })
    };
  } catch (error) {
    console.error('Error calculating trending tags:', error);
    return {
      statusCode: 500,
      body: JSON.stringify({ error: 'Internal server error' })
    };
  }
};
```

#### 2. EventBridge ê¸°ë°˜ ì´ë²¤íŠ¸ ì²˜ë¦¬

```yaml
# serverless.yml
service: dongne-events

provider:
  name: aws
  runtime: nodejs18.x
  region: ap-northeast-2
  environment:
    ELASTICSEARCH_ENDPOINT: ${env:ELASTICSEARCH_ENDPOINT}
    REDIS_URL: ${env:REDIS_URL}

functions:
  processTrendingTags:
    handler: src/trending.calculateTrendingTags
    events:
      - schedule: rate(1 hour)

  processUserAnalytics:
    handler: src/analytics.processUserBehavior
    events:
      - eventBridge:
          pattern:
            source:
              - dongne.qa-service
            detail-type:
              - Question Created
              - Answer Created

  sendDailyDigest:
    handler: src/digest.sendDailyDigest
    events:
      - schedule: cron(0 9 * * ? *)

  processImageUpload:
    handler: src/images.processImageUpload
    events:
      - s3:
          bucket: dongne-uploads
          event: s3:ObjectCreated:*
          rules:
            - prefix: images/
            - suffix: .jpg
```

---

## ğŸ“ˆ í™•ì¥ì„± ì„¤ê³„ ì „ëµ

### 1. ìˆ˜í‰ í™•ì¥ (Horizontal Scaling)

#### Auto Scaling ì •ì±…

```typescript
// ìë™ ìŠ¤ì¼€ì¼ë§ ê·œì¹™ ì •ì˜
interface ScalingPolicy {
  service: string;
  minInstances: number;
  maxInstances: number;
  targetMetrics: ScalingMetric[];
  scaleUpCooldown: number;
  scaleDownCooldown: number;
}

const scalingPolicies: ScalingPolicy[] = [
  {
    service: "qa-service",
    minInstances: 3,
    maxInstances: 50,
    targetMetrics: [
      { name: "cpu", target: 70, type: "percentage" },
      { name: "memory", target: 80, type: "percentage" },
      { name: "request_rate", target: 1000, type: "requests_per_minute" }
    ],
    scaleUpCooldown: 300, // 5ë¶„
    scaleDownCooldown: 600 // 10ë¶„
  },
  {
    service: "notification-service",
    minInstances: 2,
    maxInstances: 30,
    targetMetrics: [
      { name: "queue_depth", target: 100, type: "count" },
      { name: "message_processing_time", target: 1000, type: "milliseconds" }
    ],
    scaleUpCooldown: 120, // 2ë¶„ (ì•Œë¦¼ì€ ë¹ ë¥¸ í™•ì¥ í•„ìš”)
    scaleDownCooldown: 600
  }
];
```

#### ë¡œë“œ ë°¸ëŸ°ì‹± ì „ëµ

```yaml
# Application Load Balancer ì„¤ì •
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dongne-ingress
  annotations:
    kubernetes.io/ingress.class: "aws-load-balancer-controller"
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/load-balancer-attributes: |
      routing.http2.enabled=true,
      idle_timeout.timeout_seconds=60,
      access_logs.s3.enabled=true,
      access_logs.s3.bucket=dongne-alb-logs
    alb.ingress.kubernetes.io/ssl-redirect: '443'
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:ap-northeast-2:123456789:certificate/xxx
spec:
  rules:
  - host: api.dongnemuleoboa.com
    http:
      paths:
      - path: /api/v1/auth
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 80
      - path: /api/v1/questions
        pathType: Prefix
        backend:
          service:
            name: qa-service
            port:
              number: 80
      - path: /api/v1/search
        pathType: Prefix
        backend:
          service:
            name: search-service
            port:
              number: 80
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥ ì „ëµ

#### Read Replica êµ¬ì„±

```typescript
// ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬ì
class DatabaseManager {
  private masterConnection: Pool;
  private replicaConnections: Pool[];
  private replicaIndex = 0;

  constructor() {
    this.masterConnection = new Pool({
      host: process.env.DB_MASTER_HOST,
      port: 5432,
      database: 'dongne_db',
      user: process.env.DB_USER,
      password: process.env.DB_PASSWORD,
      max: 20,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000,
    });

    this.replicaConnections = [
      new Pool({
        host: process.env.DB_REPLICA1_HOST,
        port: 5432,
        database: 'dongne_db',
        user: process.env.DB_USER,
        password: process.env.DB_PASSWORD,
        max: 20,
      }),
      new Pool({
        host: process.env.DB_REPLICA2_HOST,
        port: 5432,
        database: 'dongne_db',
        user: process.env.DB_USER,
        password: process.env.DB_PASSWORD,
        max: 20,
      })
    ];
  }

  // ì“°ê¸° ì‘ì—…ì€ ë§ˆìŠ¤í„°ë¡œ
  async write(query: string, params: any[]): Promise<any> {
    return this.masterConnection.query(query, params);
  }

  // ì½ê¸° ì‘ì—…ì€ ë ˆí”Œë¦¬ì¹´ë¡œ (ë¼ìš´ë“œ ë¡œë¹ˆ)
  async read(query: string, params: any[]): Promise<any> {
    const replica = this.getNextReplica();
    try {
      return await replica.query(query, params);
    } catch (error) {
      // ë ˆí”Œë¦¬ì¹´ ì‹¤íŒ¨ì‹œ ë§ˆìŠ¤í„°ë¡œ í´ë°±
      console.warn('Replica query failed, falling back to master:', error);
      return this.masterConnection.query(query, params);
    }
  }

  private getNextReplica(): Pool {
    const replica = this.replicaConnections[this.replicaIndex];
    this.replicaIndex = (this.replicaIndex + 1) % this.replicaConnections.length;
    return replica;
  }
}
```

#### ìƒ¤ë”© ì „ëµ (ë©€í‹°ë¦¬ì „ í™•ì¥ ëŒ€ë¹„)

```typescript
// ì§€ì—­ë³„ ë°ì´í„° ìƒ¤ë”©
interface ShardConfig {
  regionCode: string;
  dbConfig: {
    host: string;
    port: number;
    database: string;
  };
  isActive: boolean;
}

class ShardManager {
  private shards: Map<string, DatabaseManager> = new Map();
  private defaultShard: DatabaseManager;

  constructor(shardConfigs: ShardConfig[]) {
    shardConfigs.forEach(config => {
      if (config.isActive) {
        const dbManager = new DatabaseManager(config.dbConfig);
        this.shards.set(config.regionCode, dbManager);
      }
    });

    // ì œì£¼ë„ë¥¼ ê¸°ë³¸ ìƒ¤ë“œë¡œ ì„¤ì •
    this.defaultShard = this.shards.get('jeju') || this.shards.values().next().value;
  }

  getShardByRegion(regionCode: string): DatabaseManager {
    return this.shards.get(regionCode) || this.defaultShard;
  }

  // ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ë°˜ ìƒ¤ë“œ ì„ íƒ
  getShardByLocation(latitude: number, longitude: number): DatabaseManager {
    const regionCode = this.determineRegionByCoordinates(latitude, longitude);
    return this.getShardByRegion(regionCode);
  }

  private determineRegionByCoordinates(lat: number, lng: number): string {
    // ì œì£¼ë„ ì¢Œí‘œ ë²”ìœ„: 33.1-33.6, 126.1-126.9
    if (lat >= 33.1 && lat <= 33.6 && lng >= 126.1 && lng <= 126.9) {
      return 'jeju';
    }
    // ë¶€ì‚° ì¢Œí‘œ ë²”ìœ„ (í–¥í›„ í™•ì¥)
    if (lat >= 35.0 && lat <= 35.3 && lng >= 128.9 && lng <= 129.3) {
      return 'busan';
    }

    return 'default';
  }
}
```

### 3. CDN ë° ìºì‹± ì „ëµ

#### ë‹¤ì¸µ ìºì‹± ì•„í‚¤í…ì²˜

```typescript
// ìºì‹± ê³„ì¸µ ê´€ë¦¬ì
class CacheManager {
  private l1Cache: NodeCache; // ë©”ëª¨ë¦¬ ìºì‹œ (1ë¶„)
  private l2Cache: Redis;     // Redis ìºì‹œ (1ì‹œê°„)
  private l3Cache: string;    // CDN ìºì‹œ (1ì¼)

  constructor() {
    this.l1Cache = new NodeCache({ stdTTL: 60 }); // 1ë¶„
    this.l2Cache = new Redis(process.env.REDIS_URL);
  }

  async get(key: string): Promise<any> {
    // L1 ìºì‹œ í™•ì¸
    let value = this.l1Cache.get(key);
    if (value !== undefined) {
      return value;
    }

    // L2 ìºì‹œ í™•ì¸
    const redisValue = await this.l2Cache.get(key);
    if (redisValue) {
      value = JSON.parse(redisValue);
      this.l1Cache.set(key, value); // L1ì— ë³µì‚¬
      return value;
    }

    return null;
  }

  async set(key: string, value: any, ttl?: number): Promise<void> {
    // L1 ìºì‹œ ì €ì¥
    this.l1Cache.set(key, value, ttl || 60);

    // L2 ìºì‹œ ì €ì¥
    await this.l2Cache.setex(key, ttl || 3600, JSON.stringify(value));
  }

  async invalidate(pattern: string): Promise<void> {
    // L1 ìºì‹œ ë¬´íš¨í™”
    this.l1Cache.flushAll();

    // L2 ìºì‹œ ë¬´íš¨í™”
    const keys = await this.l2Cache.keys(pattern);
    if (keys.length > 0) {
      await this.l2Cache.del(...keys);
    }
  }
}

// ìºì‹± ì „ëµë³„ ì„¤ì •
const cacheStrategies = {
  questions: {
    key: (id: string) => `question:${id}`,
    ttl: 1800, // 30ë¶„
    strategy: 'cache-aside'
  },
  userProfiles: {
    key: (id: string) => `user:${id}`,
    ttl: 3600, // 1ì‹œê°„
    strategy: 'write-through'
  },
  searchResults: {
    key: (query: string) => `search:${Buffer.from(query).toString('base64')}`,
    ttl: 600, // 10ë¶„
    strategy: 'cache-aside'
  },
  trendingTags: {
    key: () => 'trending:tags',
    ttl: 900, // 15ë¶„
    strategy: 'refresh-ahead'
  }
};
```

---

## ğŸ›¡ï¸ ê³ ê°€ìš©ì„± ë° ì¬í•´ë³µêµ¬

### 1. Multi-AZ ë°°í¬

#### ê°€ìš©ì˜ì—­ë³„ ë¦¬ì†ŒìŠ¤ ë¶„ì‚°

```yaml
# ì§€ì—­ë³„ ë°°í¬ ì„¤ì •
apiVersion: v1
kind: ConfigMap
metadata:
  name: availability-zones
data:
  primary-az: "ap-northeast-2a"
  secondary-az: "ap-northeast-2b"
  tertiary-az: "ap-northeast-2c"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qa-service-multi-az
spec:
  replicas: 6
  selector:
    matchLabels:
      app: qa-service
  template:
    metadata:
      labels:
        app: qa-service
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: qa-service
            topologyKey: "topology.kubernetes.io/zone"
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - ap-northeast-2a
                - ap-northeast-2b
                - ap-northeast-2c
      containers:
      - name: qa-service
        image: dongne/qa-service:v1.0.0
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "400m"
```

### 2. ë°ì´í„° ë°±ì—… ë° ë³µêµ¬

#### ìë™í™”ëœ ë°±ì—… ì‹œìŠ¤í…œ

```typescript
// ë°±ì—… ê´€ë¦¬ ì‹œìŠ¤í…œ
class BackupManager {
  private s3Client: S3Client;
  private databases: DatabaseConnection[];

  constructor() {
    this.s3Client = new S3Client({ region: 'ap-northeast-2' });
    this.databases = [
      { name: 'postgres-master', type: 'postgresql' },
      { name: 'redis-cluster', type: 'redis' },
      { name: 'elasticsearch', type: 'elasticsearch' }
    ];
  }

  async createBackup(schedule: BackupSchedule): Promise<BackupResult[]> {
    const results: BackupResult[] = [];

    for (const db of this.databases) {
      try {
        const backupResult = await this.backupDatabase(db, schedule);
        results.push(backupResult);
      } catch (error) {
        console.error(`Backup failed for ${db.name}:`, error);
        results.push({
          database: db.name,
          success: false,
          error: error.message
        });
      }
    }

    return results;
  }

  private async backupDatabase(db: DatabaseConnection, schedule: BackupSchedule): Promise<BackupResult> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const backupKey = `backups/${db.name}/${schedule.type}/${timestamp}`;

    switch (db.type) {
      case 'postgresql':
        return this.backupPostgreSQL(db, backupKey);
      case 'redis':
        return this.backupRedis(db, backupKey);
      case 'elasticsearch':
        return this.backupElasticsearch(db, backupKey);
      default:
        throw new Error(`Unsupported database type: ${db.type}`);
    }
  }

  private async backupPostgreSQL(db: DatabaseConnection, backupKey: string): Promise<BackupResult> {
    // pg_dumpë¥¼ ì‚¬ìš©í•œ PostgreSQL ë°±ì—…
    const dumpCommand = `pg_dump ${process.env.DATABASE_URL} --format=custom --compress=9`;
    const backupStream = spawn('pg_dump', [
      process.env.DATABASE_URL!,
      '--format=custom',
      '--compress=9'
    ]);

    // S3ì— ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ
    const uploadParams = {
      Bucket: 'dongne-backups',
      Key: `${backupKey}.dump`,
      Body: backupStream.stdout,
      StorageClass: 'GLACIER' as const
    };

    await this.s3Client.send(new PutObjectCommand(uploadParams));

    return {
      database: db.name,
      success: true,
      backupLocation: `s3://dongne-backups/${backupKey}.dump`,
      size: await this.getBackupSize(backupKey),
      timestamp: new Date()
    };
  }

  // ë°±ì—… ìŠ¤ì¼€ì¤„ ê´€ë¦¬
  setupBackupSchedules(): void {
    const schedules: BackupSchedule[] = [
      {
        type: 'full',
        cron: '0 2 * * *', // ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        retention: 30 // 30ì¼ ë³´ê´€
      },
      {
        type: 'incremental',
        cron: '0 */6 * * *', // 6ì‹œê°„ë§ˆë‹¤
        retention: 7 // 7ì¼ ë³´ê´€
      },
      {
        type: 'transaction-log',
        cron: '*/15 * * * *', // 15ë¶„ë§ˆë‹¤
        retention: 1 // 1ì¼ ë³´ê´€
      }
    ];

    schedules.forEach(schedule => {
      cron.schedule(schedule.cron, async () => {
        await this.createBackup(schedule);
        await this.cleanupOldBackups(schedule);
      });
    });
  }
}
```

### 3. ì¥ì•  ê°ì§€ ë° ìë™ ë³µêµ¬

#### Health Check ì‹œìŠ¤í…œ

```typescript
// ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬ ì‹œìŠ¤í…œ
class HealthCheckManager {
  private services: ServiceEndpoint[];
  private alertManager: AlertManager;

  constructor() {
    this.services = [
      { name: 'user-service', url: 'http://user-service/health', timeout: 5000 },
      { name: 'qa-service', url: 'http://qa-service/health', timeout: 5000 },
      { name: 'notification-service', url: 'http://notification-service/health', timeout: 3000 },
      { name: 'postgres-master', url: 'postgres://master/health', timeout: 10000 },
      { name: 'redis-cluster', url: 'redis://cluster/health', timeout: 3000 }
    ];
    this.alertManager = new AlertManager();
  }

  async performHealthChecks(): Promise<HealthCheckResult[]> {
    const promises = this.services.map(service => this.checkService(service));
    return Promise.allSettled(promises).then(results =>
      results.map((result, index) => ({
        service: this.services[index].name,
        healthy: result.status === 'fulfilled' && result.value.healthy,
        responseTime: result.status === 'fulfilled' ? result.value.responseTime : null,
        error: result.status === 'rejected' ? result.reason : null,
        timestamp: new Date()
      }))
    );
  }

  private async checkService(service: ServiceEndpoint): Promise<ServiceHealth> {
    const startTime = Date.now();

    try {
      const response = await axios.get(service.url, {
        timeout: service.timeout,
        validateStatus: (status) => status < 500
      });

      return {
        healthy: response.status === 200,
        responseTime: Date.now() - startTime,
        details: response.data
      };
    } catch (error) {
      throw {
        healthy: false,
        responseTime: Date.now() - startTime,
        error: error.message
      };
    }
  }

  async handleUnhealthyService(service: string, error: any): Promise<void> {
    // 1. ì¦‰ì‹œ ì•Œë¦¼ ë°œì†¡
    await this.alertManager.sendAlert({
      severity: 'critical',
      service,
      message: `Service ${service} is unhealthy: ${error}`,
      timestamp: new Date()
    });

    // 2. ìë™ ë³µêµ¬ ì‹œë„
    await this.attemptAutoRecovery(service);

    // 3. íŠ¸ë˜í”½ ì¬ë¼ìš°íŒ…
    await this.rerouteTraffic(service);
  }

  private async attemptAutoRecovery(service: string): Promise<void> {
    const recoveryActions = {
      'user-service': async () => {
        // Pod ì¬ì‹œì‘
        await this.restartPods(service);
      },
      'postgres-master': async () => {
        // ë§ˆìŠ¤í„° ì¥ì• ì‹œ ìŠ¬ë ˆì´ë¸Œë¥¼ ë§ˆìŠ¤í„°ë¡œ ìŠ¹ê²©
        await this.promoteSlaveToMaster();
      },
      'redis-cluster': async () => {
        // Redis í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„±
        await this.reconfigureRedisCluster();
      }
    };

    const action = recoveryActions[service];
    if (action) {
      await action();
    }
  }
}
```

### 4. ì¬í•´ë³µêµ¬ (Disaster Recovery)

#### Cross-Region ë°±ì—… ë° ë³µì œ

```yaml
# ì¬í•´ë³µêµ¬ ì„¤ì •
apiVersion: v1
kind: ConfigMap
metadata:
  name: dr-config
data:
  primary-region: "ap-northeast-2"  # ì„œìš¸
  dr-region: "ap-northeast-1"       # ë„ì¿„
  rto: "4h"                         # Recovery Time Objective
  rpo: "1h"                         # Recovery Point Objective

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dr-sync-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dr-sync
  template:
    metadata:
      labels:
        app: dr-sync
    spec:
      containers:
      - name: dr-sync
        image: dongne/dr-sync:v1.0.0
        env:
        - name: PRIMARY_REGION
          value: "ap-northeast-2"
        - name: DR_REGION
          value: "ap-northeast-1"
        - name: SYNC_INTERVAL
          value: "3600" # 1ì‹œê°„ë§ˆë‹¤ ë™ê¸°í™”
        command:
        - /bin/sh
        - -c
        - |
          while true; do
            echo "Starting DR sync..."

            # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ëƒ…ìƒ·ì„ DR ë¦¬ì „ìœ¼ë¡œ ë³µì‚¬
            aws rds copy-db-snapshot \
              --source-db-snapshot-identifier dongne-db-snapshot-$(date +%Y%m%d%H) \
              --target-db-snapshot-identifier dongne-db-dr-$(date +%Y%m%d%H) \
              --source-region ap-northeast-2 \
              --region ap-northeast-1

            # S3 ë°ì´í„°ë¥¼ DR ë¦¬ì „ìœ¼ë¡œ ë™ê¸°í™”
            aws s3 sync s3://dongne-uploads s3://dongne-uploads-dr --region ap-northeast-1

            # Elasticsearch ìŠ¤ëƒ…ìƒ·ì„ DR ë¦¬ì „ìœ¼ë¡œ ë³µì‚¬
            curl -X PUT "elasticsearch-dr.ap-northeast-1.es.amazonaws.com/_snapshot/dr-repo/snapshot-$(date +%Y%m%d%H)" \
              -H 'Content-Type: application/json' \
              -d '{"indices": "*", "ignore_unavailable": true}'

            echo "DR sync completed"
            sleep $SYNC_INTERVAL
          done
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

#### ì¸ë±ìŠ¤ ìµœì í™” ì „ëµ

```sql
-- ì§ˆë¬¸ ê²€ìƒ‰ ìµœì í™” ì¸ë±ìŠ¤
CREATE INDEX CONCURRENTLY idx_questions_region_category_created
ON questions (region_code, category, created_at DESC);

CREATE INDEX CONCURRENTLY idx_questions_location_gist
ON questions USING GIST (location);

CREATE INDEX CONCURRENTLY idx_questions_hashtags_gin
ON questions USING GIN (hashtags);

CREATE INDEX CONCURRENTLY idx_questions_fulltext
ON questions USING GIN (to_tsvector('korean', title || ' ' || content));

-- ë‹µë³€ ê²€ìƒ‰ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_answers_question_created
ON answers (question_id, created_at DESC);

CREATE INDEX CONCURRENTLY idx_answers_user_accepted
ON answers (user_id, is_accepted, created_at DESC);

-- ì‚¬ìš©ì í™œë™ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_users_region_verified
ON users (region_code, is_local_verified, last_active_at DESC);

-- í¬ì¸íŠ¸ ê±°ë˜ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_point_transactions_user_created
ON point_transactions (user_id, created_at DESC);

-- íŒŒí‹°ì…”ë‹ì„ í†µí•œ ì„±ëŠ¥ ê°œì„ 
CREATE TABLE questions_partitioned (
    LIKE questions INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- ì›”ë³„ íŒŒí‹°ì…˜ ìƒì„±
CREATE TABLE questions_2024_01 PARTITION OF questions_partitioned
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE questions_2024_02 PARTITION OF questions_partitioned
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

#### ì¿¼ë¦¬ ìµœì í™”

```typescript
// ìµœì í™”ëœ ì§ˆë¬¸ ëª©ë¡ ì¡°íšŒ
class OptimizedQuestionService {
  private readonly QUESTIONS_PER_PAGE = 20;

  async getQuestions(params: QuestionListParams): Promise<PaginatedQuestions> {
    const { region, category, hashtags, page = 1, sortBy = 'created_at' } = params;

    // ê¸°ë³¸ ì¿¼ë¦¬ ë¹Œë”
    let query = this.db
      .select([
        'q.id',
        'q.title',
        'q.content',
        'q.hashtags',
        'q.created_at',
        'q.urgency',
        'u.nickname',
        'u.region_code',
        'u.is_local_verified',
        // ë‹µë³€ ìˆ˜ë¥¼ ì„œë¸Œì¿¼ë¦¬ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°íšŒ
        this.db.raw(`(
          SELECT COUNT(*) FROM answers a
          WHERE a.question_id = q.id
        ) as answer_count`),
        // ì±„íƒëœ ë‹µë³€ ì—¬ë¶€
        this.db.raw(`(
          SELECT EXISTS(
            SELECT 1 FROM answers a
            WHERE a.question_id = q.id AND a.is_accepted = true
          )
        ) as has_accepted_answer`)
      ])
      .from('questions as q')
      .join('users as u', 'q.user_id', 'u.id')
      .where('q.status', 'active')
      .limit(this.QUESTIONS_PER_PAGE)
      .offset((page - 1) * this.QUESTIONS_PER_PAGE);

    // ì¡°ê±´ë¶€ í•„í„°ë§ (ì¸ë±ìŠ¤ í™œìš©)
    if (region) {
      query = query.where('q.region_code', region);
    }

    if (category) {
      query = query.where('q.category', category);
    }

    if (hashtags?.length > 0) {
      query = query.where(this.db.raw('q.hashtags && ?', [hashtags]));
    }

    // ì •ë ¬ ìµœì í™”
    switch (sortBy) {
      case 'created_at':
        query = query.orderBy('q.created_at', 'desc');
        break;
      case 'popularity':
        // ë‹µë³€ ìˆ˜ + ì¢‹ì•„ìš” ìˆ˜ ê¸°ë°˜ ì •ë ¬
        query = query.orderBy(
          this.db.raw(`(
            SELECT COUNT(*) FROM answers a WHERE a.question_id = q.id
          ) + (
            SELECT COUNT(*) FROM question_likes ql WHERE ql.question_id = q.id
          )`),
          'desc'
        );
        break;
      case 'urgent':
        query = query
          .orderBy('q.urgency', 'desc')
          .orderBy('q.created_at', 'desc');
        break;
    }

    const questions = await query;

    // ë³„ë„ ì¿¼ë¦¬ë¡œ ì´ ê°œìˆ˜ ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)
    const totalCount = await this.getCachedQuestionCount(params);

    return {
      questions,
      pagination: {
        current_page: page,
        per_page: this.QUESTIONS_PER_PAGE,
        total: totalCount,
        total_pages: Math.ceil(totalCount / this.QUESTIONS_PER_PAGE)
      }
    };
  }

  private async getCachedQuestionCount(params: QuestionListParams): Promise<number> {
    const cacheKey = `question_count:${JSON.stringify(params)}`;

    // ìºì‹œì—ì„œ ì¡°íšŒ
    const cached = await this.cache.get(cacheKey);
    if (cached) {
      return parseInt(cached);
    }

    // DBì—ì„œ ì¡°íšŒ
    const result = await this.db('questions')
      .count('* as total')
      .where('status', 'active')
      .modify((query) => {
        if (params.region) query.where('region_code', params.region);
        if (params.category) query.where('category', params.category);
        if (params.hashtags?.length > 0) {
          query.where(this.db.raw('hashtags && ?', [params.hashtags]));
        }
      })
      .first();

    const count = result.total;

    // 5ë¶„ê°„ ìºì‹œ
    await this.cache.setex(cacheKey, 300, count.toString());

    return count;
  }
}
```

### 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ìµœì í™”

#### ì—°ê²° í’€ ìµœì í™”

```typescript
// ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì„¤ì •
class OptimizedConnectionPool {
  private pools: Map<string, Pool> = new Map();

  constructor() {
    this.initializePools();
  }

  private initializePools(): void {
    // ë§ˆìŠ¤í„° DB í’€ (ì“°ê¸° ì‘ì—…ìš©)
    this.pools.set('master', new Pool({
      host: process.env.DB_MASTER_HOST,
      port: 5432,
      database: 'dongne_db',
      user: process.env.DB_USER,
      password: process.env.DB_PASSWORD,

      // ì—°ê²° í’€ ìµœì í™” ì„¤ì •
      min: 5,                    // ìµœì†Œ ì—°ê²° ìˆ˜
      max: 20,                   // ìµœëŒ€ ì—°ê²° ìˆ˜
      idleTimeoutMillis: 30000,  // 30ì´ˆ í›„ ìœ íœ´ ì—°ê²° ì •ë¦¬
      connectionTimeoutMillis: 2000, // 2ì´ˆ ì—°ê²° íƒ€ì„ì•„ì›ƒ

      // PostgreSQL ìµœì í™” ì„¤ì •
      statement_timeout: 30000,   // 30ì´ˆ ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ
      query_timeout: 30000,
      application_name: 'dongne-api',

      // ì—°ê²° ìƒíƒœ ê²€ì¦
      keepAlive: true,
      keepAliveInitialDelayMillis: 10000,
    }));

    // ì½ê¸° ì „ìš© ë ˆí”Œë¦¬ì¹´ í’€
    this.pools.set('replica', new Pool({
      host: process.env.DB_REPLICA_HOST,
      port: 5432,
      database: 'dongne_db',
      user: process.env.DB_USER,
      password: process.env.DB_PASSWORD,

      min: 3,
      max: 30,  // ì½ê¸°ëŠ” ë” ë§ì€ ì—°ê²° í—ˆìš©
      idleTimeoutMillis: 60000,
      connectionTimeoutMillis: 2000,

      statement_timeout: 15000,  // ì½ê¸°ëŠ” ë” ì§§ì€ íƒ€ì„ì•„ì›ƒ
      query_timeout: 15000,
      application_name: 'dongne-api-readonly',
    }));
  }

  getPool(type: 'master' | 'replica' = 'master'): Pool {
    return this.pools.get(type)!;
  }

  // ì—°ê²° í’€ ìƒíƒœ ëª¨ë‹ˆí„°ë§
  getPoolStatus(): PoolStatus[] {
    return Array.from(this.pools.entries()).map(([name, pool]) => ({
      name,
      totalConnections: pool.totalCount,
      idleConnections: pool.idleCount,
      waitingClients: pool.waitingCount
    }));
  }
}
```

#### ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”

```typescript
// ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬ ì‹œìŠ¤í…œ
class BackgroundJobProcessor {
  private queues: Map<string, Queue> = new Map();
  private workers: Map<string, Worker> = new Map();

  constructor() {
    this.initializeQueues();
    this.startWorkers();
  }

  private initializeQueues(): void {
    const queueConfigs = [
      {
        name: 'notification',
        concurrency: 10,
        priority: 'high',
        retryAttempts: 3
      },
      {
        name: 'email',
        concurrency: 5,
        priority: 'medium',
        retryAttempts: 5
      },
      {
        name: 'analytics',
        concurrency: 3,
        priority: 'low',
        retryAttempts: 2
      },
      {
        name: 'image-processing',
        concurrency: 2,
        priority: 'medium',
        retryAttempts: 3
      }
    ];

    queueConfigs.forEach(config => {
      const queue = new Queue(config.name, {
        redis: { host: process.env.REDIS_HOST, port: 6379 },
        defaultJobOptions: {
          attempts: config.retryAttempts,
          backoff: 'exponential',
          removeOnComplete: 100,
          removeOnFail: 50
        }
      });

      this.queues.set(config.name, queue);
    });
  }

  private startWorkers(): void {
    // ì•Œë¦¼ ì²˜ë¦¬ ì›Œì»¤
    this.workers.set('notification', new Worker('notification', async (job) => {
      const { userId, notification } = job.data;
      await this.processNotification(userId, notification);
    }, {
      concurrency: 10,
      limiter: {
        max: 1000,
        duration: 60000 // ë¶„ë‹¹ 1000ê°œ ì œí•œ
      }
    }));

    // ì´ë©”ì¼ ì²˜ë¦¬ ì›Œì»¤
    this.workers.set('email', new Worker('email', async (job) => {
      const { email, subject, content } = job.data;
      await this.sendEmail(email, subject, content);
    }, {
      concurrency: 5,
      limiter: {
        max: 100,
        duration: 60000 // ë¶„ë‹¹ 100ê°œ ì œí•œ
      }
    }));

    // ì´ë¯¸ì§€ ì²˜ë¦¬ ì›Œì»¤
    this.workers.set('image-processing', new Worker('image-processing', async (job) => {
      const { imageUrl, options } = job.data;
      await this.processImage(imageUrl, options);
    }, {
      concurrency: 2 // CPU ì§‘ì•½ì  ì‘ì—…ì´ë¯€ë¡œ ë‚®ì€ ë™ì‹œì„±
    }));
  }

  async addJob(queueName: string, jobData: any, options?: JobOptions): Promise<void> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }

    await queue.add(jobData, {
      priority: options?.priority || 0,
      delay: options?.delay || 0,
      attempts: options?.attempts || 3
    });
  }

  // ë°°ì¹˜ ì‘ì—… ì²˜ë¦¬
  async addBulkJobs(queueName: string, jobs: BulkJobData[]): Promise<void> {
    const queue = this.queues.get(queueName);
    if (!queue) {
      throw new Error(`Queue ${queueName} not found`);
    }

    const bulkJobs = jobs.map(job => ({
      name: job.name || 'bulk-job',
      data: job.data,
      opts: {
        priority: job.priority || 0,
        attempts: job.attempts || 3
      }
    }));

    await queue.addBulk(bulkJobs);
  }
}
```

### 3. í”„ë¡ íŠ¸ì—”ë“œ ìµœì í™”

#### React ì„±ëŠ¥ ìµœì í™”

```typescript
// ë©”ëª¨ì´ì œì´ì…˜ì„ í™œìš©í•œ ì»´í¬ë„ŒíŠ¸ ìµœì í™”
import { memo, useMemo, useCallback, useState, useEffect } from 'react';
import { useVirtualizer } from '@tanstack/react-virtual';

// ì§ˆë¬¸ ëª©ë¡ ì»´í¬ë„ŒíŠ¸ ìµœì í™”
const QuestionList = memo(({ questions, onQuestionClick }) => {
  const parentRef = useRef<HTMLDivElement>(null);

  // ê°€ìƒ ìŠ¤í¬ë¡¤ë§ìœ¼ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬
  const rowVirtualizer = useVirtualizer({
    count: questions.length,
    getScrollElement: () => parentRef.current,
    estimateSize: () => 120, // ì˜ˆìƒ ë†’ì´
    overscan: 5 // ë²„í¼ ì•„ì´í…œ ìˆ˜
  });

  const virtualItems = rowVirtualizer.getVirtualItems();

  return (
    <div ref={parentRef} className="h-96 overflow-auto">
      <div
        style={{
          height: `${rowVirtualizer.getTotalSize()}px`,
          width: '100%',
          position: 'relative',
        }}
      >
        {virtualItems.map((virtualItem) => (
          <div
            key={virtualItem.key}
            style={{
              position: 'absolute',
              top: 0,
              left: 0,
              width: '100%',
              height: `${virtualItem.size}px`,
              transform: `translateY(${virtualItem.start}px)`,
            }}
          >
            <QuestionItem
              question={questions[virtualItem.index]}
              onClick={onQuestionClick}
            />
          </div>
        ))}
      </div>
    </div>
  );
});

// ê°œë³„ ì§ˆë¬¸ ì•„ì´í…œ ìµœì í™”
const QuestionItem = memo(({ question, onClick }) => {
  const handleClick = useCallback(() => {
    onClick(question.id);
  }, [question.id, onClick]);

  // í•´ì‹œíƒœê·¸ ë Œë”ë§ ìµœì í™”
  const hashtagElements = useMemo(() => (
    question.hashtags.map(tag => (
      <span key={tag} className="hashtag">
        #{tag}
      </span>
    ))
  ), [question.hashtags]);

  return (
    <div className="question-item" onClick={handleClick}>
      <h3>{question.title}</h3>
      <p>{question.content.substring(0, 100)}...</p>
      <div className="hashtags">{hashtagElements}</div>
      <div className="meta">
        <span>{question.user.nickname}</span>
        <span>{formatTimeAgo(question.created_at)}</span>
      </div>
    </div>
  );
}, (prevProps, nextProps) => {
  // ì»¤ìŠ¤í…€ ë¹„êµ í•¨ìˆ˜ë¡œ ë¶ˆí•„ìš”í•œ ë¦¬ë Œë”ë§ ë°©ì§€
  return (
    prevProps.question.id === nextProps.question.id &&
    prevProps.question.title === nextProps.question.title &&
    prevProps.question.content === nextProps.question.content
  );
});
```

#### ì´ë¯¸ì§€ ìµœì í™”

```typescript
// Next.js Image ì»´í¬ë„ŒíŠ¸ í™•ì¥
import Image from 'next/image';
import { useState } from 'react';

const OptimizedImage = ({ src, alt, width, height, priority = false, ...props }) => {
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState(false);

  // WebP ì§€ì› í™•ì¸ ë° ëŒ€ì²´ ì´ë¯¸ì§€ ì œê³µ
  const getOptimizedSrc = useCallback((originalSrc: string) => {
    if (originalSrc.includes('amazonaws.com')) {
      // S3 ì´ë¯¸ì§€ì˜ ê²½ìš° CloudFront ë³€í™˜ í™œìš©
      return originalSrc.replace(/\.(jpg|jpeg|png)$/, '.webp');
    }
    return originalSrc;
  }, []);

  return (
    <div className={`image-container ${isLoading ? 'loading' : ''}`}>
      {isLoading && (
        <div className="image-skeleton" style={{ width, height }} />
      )}
      {!error && (
        <Image
          src={getOptimizedSrc(src)}
          alt={alt}
          width={width}
          height={height}
          priority={priority}
          loading={priority ? 'eager' : 'lazy'}
          quality={85} // í’ˆì§ˆ ìµœì í™”
          sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw"
          onLoad={() => setIsLoading(false)}
          onError={() => {
            setError(true);
            setIsLoading(false);
          }}
          placeholder="blur"
          blurDataURL="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k="
          {...props}
        />
      )}
      {error && (
        <div className="image-error" style={{ width, height }}>
          <span>ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</span>
        </div>
      )}
    </div>
  );
};

// ì´ë¯¸ì§€ ì§€ì—° ë¡œë”© í›…
const useIntersectionObserver = (threshold = 0.1) => {
  const [isIntersecting, setIsIntersecting] = useState(false);
  const targetRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    const observer = new IntersectionObserver(
      ([entry]) => {
        if (entry.isIntersecting) {
          setIsIntersecting(true);
          observer.unobserve(entry.target);
        }
      },
      { threshold }
    );

    if (targetRef.current) {
      observer.observe(targetRef.current);
    }

    return () => observer.disconnect();
  }, [threshold]);

  return [targetRef, isIntersecting] as const;
};
```

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ ì„ ì •

### í”„ë¡ íŠ¸ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ

```typescript
// ê¸°ìˆ  ìŠ¤íƒ ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤
interface TechStackDecision {
  technology: string;
  alternatives: string[];
  selectedReason: string;
  pros: string[];
  cons: string[];
  futureConsiderations: string[];
}

const frontendStack: TechStackDecision[] = [
  {
    technology: "Next.js 14 (App Router)",
    alternatives: ["React SPA", "Vue.js", "Angular", "SvelteKit"],
    selectedReason: "SSR/SSG ì§€ì›ìœ¼ë¡œ SEO ìµœì í™” ë° ì´ˆê¸° ë¡œë”© ì„±ëŠ¥ í–¥ìƒ",
    pros: [
      "ì„œë²„ì‚¬ì´ë“œ ë Œë”ë§ìœ¼ë¡œ SEO ì¹œí™”ì ",
      "ì´ë¯¸ì§€ ìµœì í™” ìë™í™”",
      "API Routesë¡œ ë°±ì—”ë“œ ë¡œì§ í†µí•© ê°€ëŠ¥",
      "Vercel ë°°í¬ ìµœì í™”",
      "í•œêµ­ ì»¤ë®¤ë‹ˆí‹° í™œë°œ"
    ],
    cons: [
      "ëŸ¬ë‹ ì»¤ë¸Œ ì¡´ì¬",
      "ë²ˆë“¤ í¬ê¸°ê°€ í´ ìˆ˜ ìˆìŒ",
      "ì„œë²„ ìì› í•„ìš”"
    ],
    futureConsiderations: [
      "React Server Components í™œìš©",
      "Edge Runtime ìµœì í™”"
    ]
  },
  {
    technology: "TypeScript",
    alternatives: ["JavaScript", "Flow"],
    selectedReason: "ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ì˜ ì•ˆì •ì„± ë° ê°œë°œ ìƒì‚°ì„± í–¥ìƒ",
    pros: [
      "ì»´íŒŒì¼ íƒ€ì„ ì—ëŸ¬ ê²€ì¶œ",
      "IDE ì§€ì› ê°•í™”",
      "ë¦¬íŒ©í† ë§ ì•ˆì „ì„±",
      "íŒ€ í˜‘ì—… íš¨ìœ¨ì„±"
    ],
    cons: [
      "ì´ˆê¸° ê°œë°œ ì†ë„ ì €í•˜",
      "íƒ€ì… ì •ì˜ ì˜¤ë²„í—¤ë“œ"
    ],
    futureConsiderations: [
      "strict ëª¨ë“œ ì ì§„ì  ì ìš©",
      "ì œë„¤ë¦­ íƒ€ì… í™œìš© í™•ëŒ€"
    ]
  },
  {
    technology: "Tailwind CSS",
    alternatives: ["Styled Components", "Emotion", "Material-UI", "Chakra UI"],
    selectedReason: "ë¹ ë¥¸ UI ê°œë°œ ë° ì¼ê´€ëœ ë””ìì¸ ì‹œìŠ¤í…œ êµ¬ì¶•",
    pros: [
      "ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘",
      "ë²ˆë“¤ í¬ê¸° ìµœì í™”",
      "ë””ìì¸ í† í° í‘œì¤€í™”",
      "ë°˜ì‘í˜• ë””ìì¸ ìš©ì´"
    ],
    cons: [
      "HTML í´ë˜ìŠ¤ ë³µì¡ì„±",
      "ì»¤ìŠ¤í…€ ë””ìì¸ ì œì•½"
    ],
    futureConsiderations: [
      "ë””ìì¸ ì‹œìŠ¤í…œ í™•ì¥",
      "ë‹¤í¬ ëª¨ë“œ ì§€ì›"
    ]
  }
];
```

### ë°±ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ

```typescript
const backendStack: TechStackDecision[] = [
  {
    technology: "Node.js 18 LTS",
    alternatives: ["Python Django", "Java Spring", "Go", "Rust"],
    selectedReason: "JavaScript í’€ìŠ¤íƒ ê°œë°œë¡œ íŒ€ íš¨ìœ¨ì„± ìµœëŒ€í™”",
    pros: [
      "í”„ë¡ íŠ¸ì—”ë“œì™€ ì–¸ì–´ í†µì¼",
      "NPM ìƒíƒœê³„ í™œìš©",
      "ë¹„ë™ê¸° I/O ì„±ëŠ¥",
      "ë¹ ë¥¸ ê°œë°œ ì†ë„",
      "í•œêµ­ ê°œë°œì í’€ í’ë¶€"
    ],
    cons: [
      "CPU ì§‘ì•½ì  ì‘ì—… ì„±ëŠ¥ í•œê³„",
      "íƒ€ì… ì•ˆì •ì„± ë¶€ì¡± (TypeScriptë¡œ ë³´ì™„)"
    ],
    futureConsiderations: [
      "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë³„ ì–¸ì–´ ì„ íƒ ê³ ë ¤",
      "ì„±ëŠ¥ í¬ë¦¬í‹°ì»¬ ë¶€ë¶„ Go/Rust ë„ì…"
    ]
  },
  {
    technology: "Express.js + TypeScript",
    alternatives: ["Fastify", "Koa.js", "NestJS", "Hapi.js"],
    selectedReason: "ê²€ì¦ëœ ì•ˆì •ì„± ë° í’ë¶€í•œ ë¯¸ë“¤ì›¨ì–´ ìƒíƒœê³„",
    pros: [
      "ì„±ìˆ™í•œ ìƒíƒœê³„",
      "ìœ ì—°í•œ ì•„í‚¤í…ì²˜",
      "ê´‘ë²”ìœ„í•œ ì»¤ë®¤ë‹ˆí‹° ì§€ì›",
      "ë¯¸ë“¤ì›¨ì–´ í’ë¶€"
    ],
    cons: [
      "ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ ì½”ë“œ ë§ìŒ",
      "êµ¬ì¡°ì  ì œì•½ ë¶€ì¡±"
    ],
    futureConsiderations: [
      "API ì„œë¹„ìŠ¤ë³„ Fastify ê³ ë ¤",
      "GraphQL ì„œë²„ ë³„ë„ êµ¬ì¶•"
    ]
  },
  {
    technology: "PostgreSQL 15",
    alternatives: ["MySQL", "MongoDB", "CockroachDB"],
    selectedReason: "ACID ë³´ì¥ ë° ê³ ê¸‰ ê¸°ëŠ¥ ì§€ì›ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± í™•ë³´",
    pros: [
      "ACID íŠ¸ëœì­ì…˜ ë³´ì¥",
      "JSON ì§€ì› (NoSQL ìœ ì—°ì„±)",
      "ê³ ê¸‰ ì¸ë±ì‹± ì§€ì›",
      "ì§€ë¦¬ì •ë³´ ì‹œìŠ¤í…œ ì§€ì›",
      "ì½ê¸° ì„±ëŠ¥ ìš°ìˆ˜"
    ],
    cons: [
      "ìˆ˜í‰ í™•ì¥ ë³µì¡ì„±",
      "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ"
    ],
    futureConsiderations: [
      "ì½ê¸° ë ˆí”Œë¦¬ì¹´ í™•ì¥",
      "ìƒ¤ë”© ì „ëµ ìˆ˜ë¦½"
    ]
  }
];
```

### ë°ì´í„°ë² ì´ìŠ¤ ë° ìºì‹±

```typescript
const dataStack: TechStackDecision[] = [
  {
    technology: "Redis Cluster",
    alternatives: ["Memcached", "Hazelcast", "DragonflyDB"],
    selectedReason: "ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡° ì§€ì› ë° ê³ ê°€ìš©ì„± í´ëŸ¬ìŠ¤í„°ë§",
    pros: [
      "ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì… ì§€ì›",
      "Pub/Sub ë©”ì‹œì§•",
      "Lua ìŠ¤í¬ë¦½íŠ¸ ì§€ì›",
      "í´ëŸ¬ìŠ¤í„° ëª¨ë“œ ê³ ê°€ìš©ì„±",
      "í•œêµ­ í´ë¼ìš°ë“œ ì§€ì› ìš°ìˆ˜"
    ],
    cons: [
      "ë©”ëª¨ë¦¬ ê¸°ë°˜ ë¹„ìš©",
      "ë³µì¡í•œ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬"
    ],
    futureConsiderations: [
      "Redis 7.0 ì‹ ê¸°ëŠ¥ í™œìš©",
      "Redis Modules ë„ì…"
    ]
  },
  {
    technology: "Elasticsearch 8",
    alternatives: ["Apache Solr", "MeiliSearch", "Algolia"],
    selectedReason: "í•œêµ­ì–´ ê²€ìƒ‰ ìµœì í™” ë° ì‹¤ì‹œê°„ ë¶„ì„ ê¸°ëŠ¥",
    pros: [
      "í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„",
      "ì‹¤ì‹œê°„ ê²€ìƒ‰ ë° ì§‘ê³„",
      "í™•ì¥ì„± ìš°ìˆ˜",
      "ì‹œê°í™” ë„êµ¬ í’ë¶€",
      "ì˜¤í”ˆì†ŒìŠ¤"
    ],
    cons: [
      "ìì› ì‚¬ìš©ëŸ‰ ë†’ìŒ",
      "ë³µì¡í•œ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬",
      "ë¼ì´ì„ ìŠ¤ ì´ìŠˆ (ìƒìš© ê¸°ëŠ¥)"
    ],
    futureConsiderations: [
      "OpenSearch ëŒ€ì•ˆ ê²€í† ",
      "Vector ê²€ìƒ‰ í™œìš©"
    ]
  }
];
```

### í´ë¼ìš°ë“œ ë° ì¸í”„ë¼

```typescript
const infrastructureStack: TechStackDecision[] = [
  {
    technology: "AWS (Primary) + ë„¤ì´ë²„ í´ë¼ìš°ë“œ (Hybrid)",
    alternatives: ["Google Cloud", "Azure", "ë„¤ì´ë²„ í´ë¼ìš°ë“œ ë‹¨ë…"],
    selectedReason: "ê¸€ë¡œë²Œ í‘œì¤€ + í•œêµ­ íŠ¹í™” ì„œë¹„ìŠ¤ ì¡°í•©ìœ¼ë¡œ ìµœì í™”",
    pros: [
      "AWS: ê¸€ë¡œë²Œ í‘œì¤€, í’ë¶€í•œ ì„œë¹„ìŠ¤",
      "ë„¤ì´ë²„: í•œêµ­ ìµœì í™”, ì¹´ì¹´ì˜¤/ë„¤ì´ë²„ API ì—°ë™",
      "ë©€í‹° í´ë¼ìš°ë“œ ìœ„í—˜ ë¶„ì‚°",
      "ë¹„ìš© ìµœì í™” ê°€ëŠ¥"
    ],
    cons: [
      "ë³µì¡í•œ ê´€ë¦¬",
      "ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ",
      "í†µí•© ëª¨ë‹ˆí„°ë§ ì–´ë ¤ì›€"
    ],
    futureConsiderations: [
      "ì£¼ìš” ì„œë¹„ìŠ¤ AWS ì§‘ì¤‘",
      "CDN ë„¤ì´ë²„ í´ë¼ìš°ë“œ í™œìš©"
    ]
  },
  {
    technology: "Docker + Kubernetes",
    alternatives: ["Docker Swarm", "AWS ECS", "ì„œë²„ë¦¬ìŠ¤ ì „í™˜"],
    selectedReason: "ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í‘œì¤€ìœ¼ë¡œ í™•ì¥ì„± ë° ì´ì‹ì„± í™•ë³´",
    pros: [
      "í™˜ê²½ ì¼ê´€ì„±",
      "ìë™ ìŠ¤ì¼€ì¼ë§",
      "ë¬´ì¤‘ë‹¨ ë°°í¬",
      "ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±",
      "ë©€í‹° í´ë¼ìš°ë“œ ì§€ì›"
    ],
    cons: [
      "í•™ìŠµ ê³¡ì„  ê°€íŒŒë¦„",
      "ìš´ì˜ ë³µì¡ì„±",
      "ì´ˆê¸° ì„¤ì • ë¹„ìš©"
    ],
    futureConsiderations: [
      "Serverless ì „í™˜ ê²€í† ",
      "Edge Computing ë„ì…"
    ]
  }
];
```

---

## ğŸš€ ê°œë°œ ë° ë°°í¬ íŒŒì´í”„ë¼ì¸

### CI/CD íŒŒì´í”„ë¼ì¸ ì„¤ê³„

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: dongne

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run linting
      run: npm run lint

    - name: Run type checking
      run: npm run type-check

    - name: Run unit tests
      run: npm run test:unit
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379

    - name: Run integration tests
      run: npm run test:integration
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379

    - name: Generate test coverage
      run: npm run test:coverage

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}

  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Run security audit
      run: npm audit --audit-level high

    - name: Run SAST with CodeQL
      uses: github/codeql-action/init@v2
      with:
        languages: javascript

    - name: Run SAST analysis
      uses: github/codeql-action/analyze@v2

  build-and-push:
    needs: [test, security-scan]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    strategy:
      matrix:
        service: [user-service, qa-service, notification-service, search-service]

    steps:
    - uses: actions/checkout@v4

    - name: Log in to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: ./services/${{ matrix.service }}
        file: ./services/${{ matrix.service }}/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy-staging:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-2

    - name: Deploy to EKS Staging
      run: |
        aws eks update-kubeconfig --region ap-northeast-2 --name dongne-staging
        helm upgrade --install dongne-staging ./helm/dongne \
          --namespace staging \
          --create-namespace \
          --set global.environment=staging \
          --set global.imageTag=${GITHUB_SHA:0:7} \
          --wait --timeout=600s

    - name: Run smoke tests
      run: |
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=dongne --timeout=300s -n staging
        npm run test:smoke -- --baseUrl=https://staging.dongnemuleoboa.com

  deploy-production:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
    - uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-northeast-2

    - name: Deploy to EKS Production
      run: |
        aws eks update-kubeconfig --region ap-northeast-2 --name dongne-production

        # Blue-Green ë°°í¬
        helm upgrade --install dongne-green ./helm/dongne \
          --namespace production \
          --set global.environment=production \
          --set global.imageTag=${GITHUB_SHA:0:7} \
          --set ingress.className=green \
          --wait --timeout=600s

        # Health check
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=dongne,version=green --timeout=300s -n production

        # Traffic switch
        kubectl patch ingress dongne-ingress -n production --type=merge -p='{"spec":{"ingressClassName":"green"}}'

        # Cleanup old version
        sleep 300
        helm uninstall dongne-blue -n production || true

    - name: Run production smoke tests
      run: |
        npm run test:smoke -- --baseUrl=https://dongnemuleoboa.com

    - name: Notify deployment success
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#deployments'
        text: 'âœ… Production deployment successful'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

### í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬

```typescript
// í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ
interface EnvironmentConfig {
  name: string;
  database: DatabaseConfig;
  redis: RedisConfig;
  external: ExternalServiceConfig;
  monitoring: MonitoringConfig;
  scaling: ScalingConfig;
}

const environments: Record<string, EnvironmentConfig> = {
  development: {
    name: 'development',
    database: {
      host: 'localhost',
      port: 5432,
      database: 'dongne_dev',
      ssl: false,
      poolSize: 5,
      logQueries: true
    },
    redis: {
      host: 'localhost',
      port: 6379,
      cluster: false,
      password: null
    },
    external: {
      kakaoApi: {
        clientId: process.env.KAKAO_CLIENT_ID_DEV,
        redirectUri: 'http://localhost:3000/auth/kakao/callback'
      },
      awsS3: {
        bucket: 'dongne-uploads-dev',
        region: 'ap-northeast-2'
      }
    },
    monitoring: {
      logLevel: 'debug',
      enableMetrics: true,
      enableTracing: true
    },
    scaling: {
      minReplicas: 1,
      maxReplicas: 3,
      targetCPU: 80
    }
  },
  staging: {
    name: 'staging',
    database: {
      host: process.env.DB_HOST_STAGING,
      port: 5432,
      database: 'dongne_staging',
      ssl: true,
      poolSize: 10,
      logQueries: false
    },
    redis: {
      host: process.env.REDIS_HOST_STAGING,
      port: 6379,
      cluster: true,
      password: process.env.REDIS_PASSWORD
    },
    external: {
      kakaoApi: {
        clientId: process.env.KAKAO_CLIENT_ID_STAGING,
        redirectUri: 'https://staging.dongnemuleoboa.com/auth/kakao/callback'
      },
      awsS3: {
        bucket: 'dongne-uploads-staging',
        region: 'ap-northeast-2'
      }
    },
    monitoring: {
      logLevel: 'info',
      enableMetrics: true,
      enableTracing: true
    },
    scaling: {
      minReplicas: 2,
      maxReplicas: 10,
      targetCPU: 70
    }
  },
  production: {
    name: 'production',
    database: {
      host: process.env.DB_HOST_PROD,
      port: 5432,
      database: 'dongne_prod',
      ssl: true,
      poolSize: 20,
      logQueries: false
    },
    redis: {
      host: process.env.REDIS_HOST_PROD,
      port: 6379,
      cluster: true,
      password: process.env.REDIS_PASSWORD
    },
    external: {
      kakaoApi: {
        clientId: process.env.KAKAO_CLIENT_ID_PROD,
        redirectUri: 'https://dongnemuleoboa.com/auth/kakao/callback'
      },
      awsS3: {
        bucket: 'dongne-uploads-prod',
        region: 'ap-northeast-2'
      }
    },
    monitoring: {
      logLevel: 'warn',
      enableMetrics: true,
      enableTracing: false
    },
    scaling: {
      minReplicas: 3,
      maxReplicas: 50,
      targetCPU: 70
    }
  }
};

// í™˜ê²½ ì„¤ì • ë¡œë”
export class ConfigLoader {
  private static instance: ConfigLoader;
  private config: EnvironmentConfig;

  private constructor() {
    const env = process.env.NODE_ENV || 'development';
    this.config = environments[env];

    if (!this.config) {
      throw new Error(`Invalid environment: ${env}`);
    }

    this.validateConfig();
  }

  static getInstance(): ConfigLoader {
    if (!ConfigLoader.instance) {
      ConfigLoader.instance = new ConfigLoader();
    }
    return ConfigLoader.instance;
  }

  getConfig(): EnvironmentConfig {
    return this.config;
  }

  private validateConfig(): void {
    const required = [
      'database.host',
      'redis.host',
      'external.kakaoApi.clientId'
    ];

    for (const path of required) {
      const value = this.getNestedValue(this.config, path);
      if (!value) {
        throw new Error(`Missing required config: ${path}`);
      }
    }
  }

  private getNestedValue(obj: any, path: string): any {
    return path.split('.').reduce((current, key) => current?.[key], obj);
  }
}
```

---

## ğŸ’° ë¹„ìš© ìµœì í™” ì „ëµ

### 1. ë‹¨ê³„ë³„ ë¹„ìš© ê³„íš

```typescript
// ë¹„ìš© ìµœì í™” ì „ëµ
interface CostOptimizationStrategy {
  phase: string;
  expectedUsers: number;
  estimatedMonthlyCost: number;
  costBreakdown: CostBreakdown;
  optimizations: Optimization[];
}

const costStrategy: CostOptimizationStrategy[] = [
  {
    phase: "MVP (0-1K users)",
    expectedUsers: 1000,
    estimatedMonthlyCost: 200, // USD
    costBreakdown: {
      compute: 80,    // ECS Fargate
      database: 50,   // RDS t3.micro
      storage: 20,    // S3 Standard
      cdn: 10,        // CloudFront
      monitoring: 20, // CloudWatch
      other: 20       // ê¸°íƒ€
    },
    optimizations: [
      "AWS í”„ë¦¬í‹°ì–´ ìµœëŒ€ í™œìš©",
      "Spot Instance ì‚¬ìš©",
      "S3 Intelligent Tiering",
      "CloudWatch ë¡œê·¸ ë³´ì¡´ ê¸°ê°„ ìµœì í™”"
    ]
  },
  {
    phase: "Growth (1K-10K users)",
    expectedUsers: 10000,
    estimatedMonthlyCost: 800,
    costBreakdown: {
      compute: 300,   // ECS Fargate + Auto Scaling
      database: 200,  // RDS t3.medium + Read Replica
      storage: 100,   // S3 + EBS
      cdn: 50,        // CloudFront
      monitoring: 80, // DataDog + CloudWatch
      other: 70       // ë°±ì—…, ë³´ì•ˆ ë“±
    },
    optimizations: [
      "Reserved Instance ë„ì…",
      "Database ì—°ê²° í’€ë§ ìµœì í™”",
      "ì´ë¯¸ì§€ ì••ì¶• ë° WebP ë³€í™˜",
      "ìºì‹± ë ˆì´ì–´ ê°•í™”"
    ]
  },
  {
    phase: "Scale (10K-100K users)",
    expectedUsers: 100000,
    estimatedMonthlyCost: 3000,
    costBreakdown: {
      compute: 1200,  // Multi-AZ ECS + Auto Scaling
      database: 800,  // RDS r5.large + Multi-AZ
      storage: 300,   // S3 + EBS + EFS
      cdn: 200,       // CloudFront + Edge Locations
      monitoring: 300, // ê³ ê¸‰ ëª¨ë‹ˆí„°ë§
      other: 200      // ë³´ì•ˆ, ë°±ì—…, ê¸°íƒ€
    },
    optimizations: [
      "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë³„ ìµœì í™”",
      "ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”©",
      "ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ í™œìš©",
      "ë¹„ìš© ëª¨ë‹ˆí„°ë§ ìë™í™”"
    ]
  }
];
```

### 2. ìë™ ë¹„ìš© ìµœì í™”

```typescript
// ìë™ ë¹„ìš© ìµœì í™” ì‹œìŠ¤í…œ
class CostOptimizer {
  private cloudWatchClient: CloudWatchClient;
  private ec2Client: EC2Client;
  private rdsClient: RDSClient;

  constructor() {
    this.cloudWatchClient = new CloudWatchClient({ region: 'ap-northeast-2' });
    this.ec2Client = new EC2Client({ region: 'ap-northeast-2' });
    this.rdsClient = new RDSClient({ region: 'ap-northeast-2' });
  }

  async optimizeResources(): Promise<OptimizationResult[]> {
    const results: OptimizationResult[] = [];

    // 1. ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤ ì‹ë³„
    results.push(...await this.identifyUnusedResources());

    // 2. ì˜¤ë²„í”„ë¡œë¹„ì €ë‹ëœ ë¦¬ì†ŒìŠ¤ ìµœì í™”
    results.push(...await this.optimizeOverProvisionedResources());

    // 3. ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìµœì í™”
    results.push(...await this.optimizeStorageClasses());

    // 4. Reserved Instance ê¶Œì¥ì‚¬í•­
    results.push(...await this.generateRIRecommendations());

    return results;
  }

  private async identifyUnusedResources(): Promise<OptimizationResult[]> {
    const results: OptimizationResult[] = [];

    // ë¯¸ì‚¬ìš© EBS ë³¼ë¥¨ ì‹ë³„
    const volumes = await this.ec2Client.send(new DescribeVolumesCommand({
      Filters: [{ Name: 'status', Values: ['available'] }]
    }));

    for (const volume of volumes.Volumes || []) {
      if (this.isVolumeUnused(volume)) {
        results.push({
          type: 'unused_ebs_volume',
          resource: volume.VolumeId,
          potentialSavings: this.calculateEBSSavings(volume),
          recommendation: `Delete unused EBS volume ${volume.VolumeId}`,
          risk: 'low'
        });
      }
    }

    // ë¯¸ì‚¬ìš© ë¡œë“œ ë°¸ëŸ°ì„œ ì‹ë³„
    const loadBalancers = await this.elbClient.send(new DescribeLoadBalancersCommand({}));

    for (const lb of loadBalancers.LoadBalancers || []) {
      const targets = await this.getLoadBalancerTargets(lb.LoadBalancerArn);
      if (targets.length === 0) {
        results.push({
          type: 'unused_load_balancer',
          resource: lb.LoadBalancerName,
          potentialSavings: 20, // ì›” $20 ì ˆì•½
          recommendation: `Remove unused load balancer ${lb.LoadBalancerName}`,
          risk: 'medium'
        });
      }
    }

    return results;
  }

  private async optimizeOverProvisionedResources(): Promise<OptimizationResult[]> {
    const results: OptimizationResult[] = [];

    // CPU ì‚¬ìš©ë¥ ì´ ë‚®ì€ RDS ì¸ìŠ¤í„´ìŠ¤ ì‹ë³„
    const dbInstances = await this.rdsClient.send(new DescribeDBInstancesCommand({}));

    for (const instance of dbInstances.DBInstances || []) {
      const cpuUtilization = await this.getAverageCPUUtilization(
        instance.DBInstanceIdentifier!,
        'AWS/RDS'
      );

      if (cpuUtilization < 20) { // í‰ê·  CPU ì‚¬ìš©ë¥  20% ë¯¸ë§Œ
        const currentClass = instance.DBInstanceClass!;
        const recommendedClass = this.getDowngradedInstanceClass(currentClass);

        if (recommendedClass) {
          results.push({
            type: 'rds_right_sizing',
            resource: instance.DBInstanceIdentifier!,
            potentialSavings: this.calculateRDSSavings(currentClass, recommendedClass),
            recommendation: `Downgrade RDS instance from ${currentClass} to ${recommendedClass}`,
            risk: 'medium'
          });
        }
      }
    }

    return results;
  }

  private async optimizeStorageClasses(): Promise<OptimizationResult[]> {
    const results: OptimizationResult[] = [];

    // S3 ê°ì²´ì˜ ì•¡ì„¸ìŠ¤ íŒ¨í„´ ë¶„ì„
    const s3Analytics = await this.analyzeS3AccessPatterns();

    for (const bucket of s3Analytics) {
      if (bucket.infrequentlyAccessedObjects > 0) {
        results.push({
          type: 's3_storage_class_optimization',
          resource: bucket.name,
          potentialSavings: bucket.potentialSavings,
          recommendation: `Move ${bucket.infrequentlyAccessedObjects} objects to IA storage class`,
          risk: 'low'
        });
      }
    }

    return results;
  }

  // ë¹„ìš© ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
  async setupCostAlerts(): Promise<void> {
    const budgetParams = {
      Budget: {
        BudgetName: 'dongne-monthly-budget',
        BudgetLimit: {
          Amount: '1000',
          Unit: 'USD'
        },
        TimeUnit: 'MONTHLY',
        BudgetType: 'COST',
        CostFilters: {
          Service: ['Amazon Elastic Compute Cloud', 'Amazon Relational Database Service']
        }
      },
      NotificationsWithSubscribers: [
        {
          Notification: {
            NotificationType: 'ACTUAL',
            ComparisonOperator: 'GREATER_THAN',
            Threshold: 80, // 80% ì„ê³„ì 
            ThresholdType: 'PERCENTAGE'
          },
          Subscribers: [
            {
              Address: 'admin@dongnemuleoboa.com',
              SubscriptionType: 'EMAIL'
            }
          ]
        }
      ]
    };

    await this.budgetsClient.send(new CreateBudgetCommand(budgetParams));
  }
}
```

### 3. ì„œë²„ë¦¬ìŠ¤ ìš°ì„  ì „ëµ

```yaml
# ì„œë²„ë¦¬ìŠ¤ ë¹„ìš© ìµœì í™” ì„¤ì •
service: dongne-serverless-functions

provider:
  name: aws
  runtime: nodejs18.x
  region: ap-northeast-2
  memorySize: 256  # ê¸°ë³¸ ë©”ëª¨ë¦¬ (ë¹„ìš© ìµœì í™”)
  timeout: 30      # íƒ€ì„ì•„ì›ƒ ìµœì í™”

  # ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜
  environment:
    NODE_ENV: production
    AWS_NODEJS_CONNECTION_REUSE_ENABLED: 1

functions:
  # ì´ë¯¸ì§€ ì²˜ë¦¬ (CPU ì§‘ì•½ì  ì‘ì—…)
  processImage:
    handler: src/images/process.handler
    memorySize: 1024  # ì´ë¯¸ì§€ ì²˜ë¦¬ìš© ë©”ëª¨ë¦¬ ì¦ê°€
    timeout: 300      # 5ë¶„ íƒ€ì„ì•„ì›ƒ
    events:
      - s3:
          bucket: dongne-uploads
          event: s3:ObjectCreated:*
          rules:
            - prefix: images/
    # Reserved Concurrencyë¡œ ë¹„ìš© ì œì–´
    reservedConcurrency: 5

  # ì•Œë¦¼ ë°œì†¡ (ê°€ë²¼ìš´ ì‘ì—…)
  sendNotification:
    handler: src/notifications/send.handler
    memorySize: 128   # ìµœì†Œ ë©”ëª¨ë¦¬ë¡œ ë¹„ìš© ì ˆì•½
    timeout: 10       # ì§§ì€ íƒ€ì„ì•„ì›ƒ
    events:
      - sqs:
          arn: arn:aws:sqs:ap-northeast-2:123456789:notification-queue
          batchSize: 10  # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¹„ìš© ìµœì í™”
    reservedConcurrency: 10

  # ë°ì´í„° ì§‘ê³„ (ìŠ¤ì¼€ì¤„ ê¸°ë°˜)
  aggregateData:
    handler: src/analytics/aggregate.handler
    memorySize: 512
    timeout: 900      # 15ë¶„ (ìµœëŒ€)
    events:
      - schedule: cron(0 2 * * ? *)  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ (ì €ë ´í•œ ì‹œê°„ëŒ€)

# ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ í”ŒëŸ¬ê·¸ì¸
plugins:
  - serverless-bundle           # ë²ˆë“¤ í¬ê¸° ìµœì í™”
  - serverless-plugin-warmup    # ì½œë“œ ìŠ¤íƒ€íŠ¸ ìµœì í™”
  - serverless-plugin-split-stacks # ìŠ¤íƒ ë¶„í• ë¡œ ë°°í¬ ì†ë„ í–¥ìƒ

custom:
  # Lambda ìµœì í™” ì„¤ì •
  bundle:
    minify: true
    sourcemaps: false
    caching: true

  # Warmup ì„¤ì • (ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ)
  warmup:
    default:
      enabled: true
      events:
        - schedule: rate(5 minutes)
      concurrency: 1
      prewarm: true
```

ì´ ì¢…í•© ê¸°ìˆ  ì•„í‚¤í…ì²˜ ë¬¸ì„œëŠ” "ë™ë„¤ë¬¼ì–´ë´" ì„œë¹„ìŠ¤ì˜ í™•ì¥ì„±ê³¼ ì•ˆì •ì„±ì„ ê³ ë ¤í•œ í¬ê´„ì ì¸ ì‹œìŠ¤í…œ ì„¤ê³„ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ë‹¨ê³„ë³„ë¡œ ì ì§„ì ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì–´ ìˆìœ¼ë©°, ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ ìµœì í™”ë¥¼ ë™ì‹œì— ê³ ë ¤í–ˆìŠµë‹ˆë‹¤.